version: "3.9"

services:
  postgres:
    image: postgres:16
    container_name: ai_mentor_postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: ai_english_mentor
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d ai_english_mentor"]
      interval: 5s
      timeout: 5s
      retries: 10

  backend:
    build:
      context: ./backend
    container_name: ai_mentor_backend
    env_file:
      - ./backend/.env
    environment:
      DATABASE_URL: postgresql+asyncpg://postgres:postgres@postgres:5432/ai_english_mentor
      ALLOWED_ORIGINS: ${ALLOWED_ORIGINS:-http://localhost:3000}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY:-change-me-access}
      JWT_REFRESH_SECRET_KEY: ${JWT_REFRESH_SECRET_KEY:-change-me-refresh}
      DEFAULT_AI_PROVIDER: ${DEFAULT_AI_PROVIDER:-gemini}
      ENABLE_COPILOT: "${ENABLE_COPILOT:-false}"
      ENABLE_OLLAMA: "${ENABLE_OLLAMA:-false}"
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
    volumes:
      - ./backend:/app
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy

  frontend:
    build:
      context: ./frontend
    container_name: ai_mentor_frontend
    environment:
      NEXT_PUBLIC_API_BASE_URL: ${API_BASE_URL:-http://localhost:8000/api/v1}
    volumes:
      - ./frontend:/app
      - /app/node_modules
    ports:
      - "3000:3000"
    depends_on:
      - backend

volumes:
  pgdata:
